{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d581cbeefde5df",
   "metadata": {},
   "source": [
    "**Universidad de Ingeniería  y Tecnología (UTEC)**  \n",
    "Lima, Peru\n",
    "\n",
    "# Tema de Laboratorio: Classification\n",
    "\n",
    "**Alumnos**:\n",
    "\n",
    "1. Leonardo Matías Candio Ormeño\n",
    "\n",
    "1. Jeffry Hilario Quintana\n",
    "\n",
    "1. Mauricio Alvarez Julca\n",
    "\n",
    "## Find a publicly available dataset between 3 and 10 classes, with no more than 1000000 data points, and no less than 1000 data points. You can not use MNIST, but can use derivatives (you can use datasets other than images)\n",
    "\n",
    "We chose to use the [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset for this project  \n",
    "\n",
    "## Define your Training Set, Your Validation Set, and Testing Set. How will you partition your data? What is the percentile split? (Example: 80% Training, 10% Validation, 10% Testing) Why did you pick this split\n",
    "\n",
    "CIFAR-10 provides 50000 specific training images and 10000 testing images. We have also decided to randomly choose 1000 images per class to use as our validation set. As a result, the percentage split is 66.66% training, 16.66% testing and 16.66% validation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "validation_per_label = 1000\n",
    "\n",
    "data_labels = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\",\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T00:28:03.030921Z",
     "start_time": "2023-09-11T00:28:03.024815Z"
    }
   },
   "id": "86c1d99c2ed776c8"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def get_sets():\n",
    "    def load_img(_img_label, _img_position, _img_type):\n",
    "        data_path = \"../data\"\n",
    "        return np.array(Image.open(\n",
    "            f'{data_path}/{\"train\" if _img_type in [\"validation\", \"train\"] else \"test\"}/{data_labels[_img_label]}/{_img_position:04d}.png'))\n",
    "\n",
    "    validation = {_label: set(np.random.permutation(np.arange(1, 5001))[:validation_per_label].flatten()) for _label\n",
    "                  in range(10)}\n",
    "    train = {_label: {_img for _img in [i for i in range(1, 5001)] if _img not in validation[_label]} for _label in\n",
    "             range(10)}\n",
    "    test = {_label: {_img for _img in range(1, 1001)} for _label in range(10)}\n",
    "\n",
    "    _validation_set = []\n",
    "    _train_set = []\n",
    "    _test_set = []\n",
    "\n",
    "    for key, value in validation.items():\n",
    "        for image in value:\n",
    "            _validation_set.append((load_img(key, image, \"validation\"), key))\n",
    "\n",
    "    for key, value in train.items():\n",
    "        for image in value:\n",
    "            _train_set.append((load_img(key, image, \"train\"), key))\n",
    "\n",
    "    for key, value in test.items():\n",
    "        for image in value:\n",
    "            _test_set.append((load_img(key, image, \"test\"), key))\n",
    "\n",
    "    random.shuffle(_validation_set)\n",
    "    random.shuffle(_train_set)\n",
    "    random.shuffle(_test_set)\n",
    "\n",
    "    _train_images, _train_labels = zip(*_train_set)\n",
    "    _validation_images, _validation_labels = zip(*_validation_set)\n",
    "    _test_images, _test_labels = zip(*_test_set)\n",
    "\n",
    "    return np.asarray(_train_images), np.asarray(_train_labels), np.asarray(_validation_images), np.asarray(\n",
    "        _validation_labels), np.asarray(_test_images), np.asarray(_test_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T00:28:05.915925Z",
     "start_time": "2023-09-11T00:28:05.910989Z"
    }
   },
   "id": "711debdcd8d87c7c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regression without regularization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e35667f1fbb0ff0"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "train_images, train_labels, validation_images, validation_labels, test_images, test_labels = get_sets()\n",
    "model = LogisticRegression(penalty=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T00:29:34.734517Z",
     "start_time": "2023-09-11T00:29:22.255594Z"
    }
   },
   "id": "c371ee707e4d46ee"
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Leonardo Matias Candio Ormeño"
   },
   {
    "name": "Mauricio Alvarez Julca"
   },
   {
    "name": "Jeffry Hilario Quintana"
   }
  ],
  "date": "September 2023",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "title": "Segundo Laboratorio de Introduction to Machine Learning"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
